---
title: "bayesian_stats_practical_12-02-2024"
output: html_document
date: "2024-02-02"
---

## Bayesian Statistics Practical Session

Practice by running the following code. First, you will have to install the required R packages. After loading the packages, you will be able to run code which compile and run three different models in a Bayesian workflow manner. Take some time to look through model summaries and plots to understand why the models might require improvement. At the end of the practical, after assessing the results of model comparison, think of how you could improve models inference and predictions.

```{r setup, include=FALSE}
install.packages("raster")
install.packages("sf")
install.packages("tiff")
install.packages("viridis")
install.packages("devtools")
install.packages("rstan")
install.packages(c("coda","mvtnorm","devtools","loo","dagitty"))
devtools::install_github("rmcelreath/rethinking@slim")
```

Make sure that all the packages have been installed successfully. Let's load them.

```{r pressure, echo=FALSE}
library(raster)
library(sf)
library(tiff)
library(viridis)
library(rstan)
library(rethinking)
```

If all packages have loaded properly, we can continue by loading the data. Make sure that all datasets have been properly loaded.

```{r pressure, echo=FALSE}
chol_map <- read_sf("./data/buildings/deaths_by_bldg.shp")
pump_map <- read_sf("./data/pumps/pumps.shp")
snow_map <- brick('./data/SnowMap.tif')
os_map <- brick('./data/OSMap_Grayscale.tif')
```

Before building up the models, let's assess the descriptive properties of the data by mapping it on John Snow's map.

```{r pressure, echo=FALSE}
order_index <- order(chol_map$deaths)
chol_map_ordered <- chol_map[order_index, ]

chol_map_ordered$deaths <- factor(chol_map_ordered$deaths, levels=unique(chol_map_ordered$deaths))

color_palette <- viridis::plasma(length(unique(chol_map_ordered$deaths)))

palette(color_palette)

png(filename="js_scatter_colormap.png", units="in", width=8, height=8, res=200)
plotRGB(snow_map, interpolate=TRUE, maxpixels=500000000)
points(chol_map_ordered$COORD_X, chol_map_ordered$COORD_Y, col=chol_map_ordered$deaths, pch=19)
legend("topright", legend=unique(chol_map_ordered$deaths), fill=color_palette, title="Deaths")
dev.off()
while (!is.null(dev.list()))  dev.off()

```

Below, try to plot the data on the modern map pf Soho (lodaded as os_map) on your own. You can also try changing color scales or playing with other features.

```{r pressure, echo=FALSE}


```

Make sure that the data shows sensible values on the map, you should see the maximum value (15 cholera deaths) in the middle of Broad Street, near the pump.

If everything makes sense, we can continue by preparing the data for modelling:

```{r pressure, echo=FALSE}
chol_map$pump_id <- as.character(chol_map$pumpID)

chol_map$pump_idx <- as.numeric(factor(chol_map$pump_id, 
                                      levels=unique(chol_map$pump_id)))
deaths <- chol_map$deaths
distance <- chol_map$distBSpump
dz <- (distance - mean(distance)) / sd(distance) #standarised distance to improve sampling


data <- list(
  y = deaths,#cholera death counts per building
  d = dz, #distance to Broad Street pump (standarised, z-scores)
  p = chol_map$pump_idx, #id index of pump respective to building location
  h = chol_map$ID #id of each measured building 
)

data 
```
Make sure that all variables make sense and that the date list contains all the relevant variables.

Now we build up the first model and plot prior predicitve checks. The model below attempts to estimate the rate of deaths based on the proximity of pumps. Buildings within a certain area around a given pump [p] are indexed, pooled together. Try to write the mathematical formula of the model below on paper. Do the assumptions of this model make sense? Is it sufficient to answer our question and hypothesis?

```{r pressure, echo=FALSE}
####################### Model 1 ########################
#######################################################

##Compute and plot prior predictive checks
prior_model1 <- ulam(
  alist(
    ## this is the actual model
    y ~ poisson( lambda ),
    log(lambda) <- a + b[p],
    a ~ normal( 0, 1 ),
    b[p] ~ normal(0 , 1 )
  ), data=data )
prior <- extract.prior(prior_model1, n=1000, pars=c(y))

y_ppc <- link(prior_model1, post=prior, data=data)

png(filename = "model1_prior_predictives.png", units = "in", width = 8, height = 8, res = 200)
plot(NULL, xlim = range(x_seq), ylim = y_limit, type = "n", 
     ylab="Density", xlab="Deaths (y)")
for (i in 500:600) {
  dens <- density(y_ppc[i, ])#, from = min(x_seq), to = max(x_seq))
  lines(dens$x, dens$y, col = col.alpha("deepskyblue2", 0.1))
  mean_dens <- density(colMeans(y_ppc), from = min(x_seq), to = max(x_seq))
  lines(mean_dens$x, mean_dens$y, col = col.alpha("darkorange"), lty=2, lwd=3)
  obs_dens = density(chol_map$deaths)
  lines(obs_dens$x, obs_dens$y, col = col.alpha("black"), lwd=3)
}
title(main="Model 1 Prior Predictive Check")
grid(nx = NULL, ny = NULL, col = "lightgray")
dev.off()
while (!is.null(dev.list()))  dev.off()
```
There is no need to worry about the warnings yet, as we are sampling from the prior only, which means that there are no data to be considered yet. In the following lines you can try sampling the model.

```{r pressure, echo=FALSE}
##sample model to get inference data (samples)
samp_model1 <- ulam(
  alist(
    ## this is the actual model
    y ~ poisson( lambda ),
    log(lambda) <- a + b[p],
    a ~ normal( 0 , 1 ),
    b[p] ~ normal( 0 , 1 )
  ), data=data , chains=4 , log_lik=TRUE, iter=2000 )

summary(samp_model1)

prec <- precis(samp_model1, depth=2, prob=0.9)
prec <- data.frame(prec)
write.csv(prec, "model1_summary.csv")

extract <- rstan::extract #to avoid confict with other packages

png(filename = "model1_trankplots.png", units = "in", width = 12, height = 5, res = 200)
par(oma = c(0, 0, 3, 0))
trankplot(samp_model1, n_cols=2, lwd=3)
mtext("Model 1 trace rank plots", side=3, line=1, at=0.5, cex = 1.5, outer=TRUE)
dev.off()
while (!is.null(dev.list()))  dev.off()
```
That's a long summary, but no need to read it in detail. The important thing to notice is that R_hats are close to 1 and effective sample sizes (n_eff) show highe values (hopefully over 1000). Check the convergence plots (trace rank plots, or trankplots): Are chains well mixed? Did the sampling converge so we can get reliable inference?

Finally, we can plot the posterior predictive distribution. Are predictions reasonable? 

```{r pressure, echo=FALSE}
##extract posterior predictive and plot
post <- extract.samples(samp_model1, n=1000)
y_pred <- link(samp_model1, post=post, data=data)

png(filename = "model1_posterior_predictives.png", units = "in", width = 8, height = 8, res = 200)
plot(NULL, xlim = range(x_seq), ylim = y_limit, type = "n",
     xlabel="Deaths (y)", ylabel="Density")
for (i in 500:600) {
  dens <- density(y_pred[i, ])#, from = min(x_seq), to = max(x_seq))
  lines(dens$x, dens$y, col = col.alpha("limegreen", 0.1))
  mean_dens <- density(colMeans(y_pred), from = min(x_seq), to = max(x_seq))
  lines(mean_dens$x, mean_dens$y, col = col.alpha("purple"), lty=2, lwd=3)
  obs_dens = density(chol_map$deaths)
  lines(obs_dens$x, obs_dens$y, col = col.alpha("black"), lwd=3)
}
title("Model 1 Posterior Predictive Check")
grid(nx = NULL, ny = NULL, col = "lightgray")
dev.off()
while (!is.null(dev.list()))  dev.off()
```

Plotting predictions on the map could be a good idea. As these are predictions on the sampling data, they should approximate the original distribution. The map below shows that this is not the case. Maybe these could be improved with a better parametrisation or a different model.

```{r pressure, echo=FALSE}
## plot posterior predictive mean on map
chol_map$preds <- round(colMeans(y_pred), 1)
order_index <- order(chol_map$preds)
chol_map_ordered <- chol_map[order_index, ]
chol_map_ordered$preds <- factor(chol_map_ordered$preds, levels=unique(chol_map_ordered$preds))
color_palette <- viridis::plasma(length(unique(chol_map_ordered$preds)))
palette(color_palette)

png(filename="model1_preds_map.png", units="in", width=8, height=8, res=200)
plotRGB(snow_map, interpolate=TRUE, maxpixels=500000000)
points(chol_map_ordered$COORD_X, chol_map_ordered$COORD_Y, col=chol_map_ordered$preds, pch=19)
legend("topright", legend=unique(chol_map_ordered$preds), fill=color_palette, title="Predicted Deaths")
dev.off()
while (!is.null(dev.list()))  dev.off()
```

One possible reparametrisation are hyperpriors. These are priors placed inside priors (that's why they are called hyper). For example: alpha ~ Normal(m, s), where m and s are also distributions, for instance m ~ Normal(0, 1) and s ~ exponential(1). Note that s must be constrained to the positve line, as it is a standard deviation parameter ("error" values cannot be negative).

Try reparametrising the model below and sampling again (if too difficult, you can see Model 2 for an example). Has something improved?

```{r pressure, echo=FALSE}

##sample model to get inference data (samples)
samp_model1 <- ulam(
  alist(
    ## this is the actual model
    y ~ poisson( lambda ),
    log(lambda) <- a + b[p],
    a ~ normal( 0 , 1 ),
    b[p] ~ normal( 0 , 1 )
  ), data=data , chains=4 , log_lik=TRUE, iter=2000 )

prec <- precis(samp_model1, depth=2, prob=0.9)
prec <- data.frame(prec)
write.csv(prec, "model1_summary.csv")
prec

extract <- rstan::extract #to avoid confict with other packages

png(filename = "model1_trankplots.png", units = "in", width = 12, height = 5, res = 200)
par(oma = c(0, 0, 3, 0))
trankplot(samp_model1, n_cols=2, lwd=3)
mtext("Model 1 trace rank plots", side=3, line=1, at=0.5, cex = 1.5, outer=TRUE)
dev.off()
while (!is.null(dev.list()))  dev.off()

##extract posterior predictive and plot
post <- extract.samples(samp_model1, n=1000)
y_pred <- link(samp_model1, post=post, data=data)

png(filename = "model1_posterior_predictives.png", units = "in", width = 8, height = 8, res = 200)
plot(NULL, xlim = range(x_seq), ylim = y_limit, type = "n",
     xlabel="Deaths (y)", ylabel="Density")
for (i in 500:600) {
  dens <- density(y_pred[i, ])#, from = min(x_seq), to = max(x_seq))
  lines(dens$x, dens$y, col = col.alpha("limegreen", 0.1))
  mean_dens <- density(colMeans(y_pred), from = min(x_seq), to = max(x_seq))
  lines(mean_dens$x, mean_dens$y, col = col.alpha("purple"), lty=2, lwd=3)
  obs_dens = density(chol_map$deaths)
  lines(obs_dens$x, obs_dens$y, col = col.alpha("black"), lwd=3)
}
title("Model 1 Posterior Predictive Check")
grid(nx = NULL, ny = NULL, col = "lightgray")
dev.off()
while (!is.null(dev.list()))  dev.off()

## plot posterior predictive mean on map
chol_map$preds <- round(colMeans(y_pred), 1)
order_index <- order(chol_map$preds)
chol_map_ordered <- chol_map[order_index, ]
chol_map_ordered$preds <- factor(chol_map_ordered$preds, levels=unique(chol_map_ordered$preds))
color_palette <- viridis::plasma(length(unique(chol_map_ordered$preds)))
palette(color_palette)

png(filename="model1_preds_map.png", units="in", width=8, height=8, res=200)
plotRGB(snow_map, interpolate=TRUE, maxpixels=500000000)
points(chol_map_ordered$COORD_X, chol_map_ordered$COORD_Y, col=chol_map_ordered$preds, pch=19)
legend("topright", legend=unique(chol_map_ordered$preds), fill=color_palette, title="Predicted Deaths")
dev.off()
while (!is.null(dev.list()))  dev.off()


```

We already hypothesised that the Broad Street pump might be contaminated. So maybe a better predictor of average death rate could be the distance from a building to Broad Street's pump. In the model below we'll run the whole workflow in a single go, so pay attention carefully to any possible bugs.

```{r pressure, echo=FALSE}

####################### Model 2 ########################
#######################################################

##Compute and plot prior predictive checks
prior_model2 <- ulam(
  alist(
    ## this is the actual model
    y ~ poisson( lambda ),
    log(lambda) <- a[h] + b[h]*d,
    a[h] ~ normal( 0 , 1 ),
    b[h] ~ normal( 0 , 1 )
  ), data=data )
prior <- extract.prior(prior_model2, n=1000, pars=c(y))

y_ppc <- link(prior_model2, post=prior, data=data)

png(filename = "model2_prior_predictives.png", units = "in", width = 8, height = 8, res = 200)
plot(NULL, xlim = range(x_seq), ylim = y_limit, type = "n", 
     ylab="Density", xlab="Deaths (y)")
for (i in 500:600) {
  dens <- density(y_ppc[i, ])#, from = min(x_seq), to = max(x_seq))
  lines(dens$x, dens$y, col = col.alpha("deepskyblue2", 0.1))
  mean_dens <- density(colMeans(y_ppc), from = min(x_seq), to = max(x_seq))
  lines(mean_dens$x, mean_dens$y, col = col.alpha("darkorange"), lty=2, lwd=3)
  obs_dens = density(chol_map$deaths)
  lines(obs_dens$x, obs_dens$y, col = col.alpha("black"), lwd=3)
}
title(main="Model 2 Prior Predictive Check")
grid(nx = NULL, ny = NULL, col = "lightgray")
dev.off()
while (!is.null(dev.list()))  dev.off()

##sample model to get inference data (samples)
samp_model2 <- ulam(
  alist(
    ## this is the actual model
    y ~ poisson( lambda ),
    log(lambda) <- a[h] + b[h]*d,
    a[h] ~ normal( 0 , 1 ),
    b[h] ~ normal( 0 , 1 )
  ), data=data , chains=4 , log_lik=TRUE, iter=2000 )


prec <- precis(samp_model2, depth=2, prob=0.9)
prec <- data.frame(prec)
write.csv(prec, "model2_summary.csv")

extract <- rstan::extract #to avoid conflict with other packages

png(filename = "model2_trankplots.png", units = "in", width = 12, height = 5, res = 200)
par(oma = c(0, 0, 3, 0))
trankplot(samp_model2, n_cols=2, lwd=3)
mtext("Model 2 trace rank plots", side=3, line=1, at=0.5, cex = 1.5, outer=TRUE)
dev.off()
while (!is.null(dev.list()))  dev.off()

##extract posterior predictive and plot
post <- extract.samples(samp_model2, n=1000)
y_pred <- link(samp_model2, post=post, data=data)

png(filename = "model2_posterior_predictives.png", units = "in", width = 8, height = 8, res = 200)
plot(NULL, xlim = range(x_seq), ylim = y_limit, type = "n",
     xlabel="Deaths (y)", ylabel="Density")
for (i in 500:600) {
  dens <- density(y_pred[i, ])#, from = min(x_seq), to = max(x_seq))
  lines(dens$x, dens$y, col = col.alpha("limegreen", 0.1))
  mean_dens <- density(colMeans(y_pred), from = min(x_seq), to = max(x_seq))
  lines(mean_dens$x, mean_dens$y, col = col.alpha("purple"), lty=2, lwd=3)
  obs_dens = density(chol_map$deaths)
  lines(obs_dens$x, obs_dens$y, col = col.alpha("black"), lwd=3)
}
title("Model 2 Posterior Predictive Check")
grid(nx = NULL, ny = NULL, col = "lightgray")
dev.off()
while (!is.null(dev.list()))  dev.off()

## plot posterior predictive mean on map
post <- extract.samples(samp_model3, n=1000)
y_pred <- link(samp_model3, post=post, data=data)
chol_map$preds <- round(colMeans(y_pred), 1)
order_index <- order(chol_map$preds)
chol_map_ordered <- chol_map[order_index, ]
chol_map_ordered$preds <- factor(chol_map_ordered$preds, levels=unique(chol_map_ordered$preds))
color_palette <- viridis::plasma(length(unique(chol_map_ordered$preds)))
palette(color_palette)

png(filename="model2_preds_map.png", units="in", width=8, height=8, res=200)
plotRGB(snow_map, interpolate=TRUE, maxpixels=500000000)
points(chol_map_ordered$COORD_X, chol_map_ordered$COORD_Y, col=chol_map_ordered$preds, pch=19)
legend("topright", legend=unique(chol_map_ordered$preds), fill=color_palette, title="Predicted Deaths")
dev.off()
while (!is.null(dev.list()))  dev.off()

```

Do results make more sense now? Inference seems to be reasonable, but why is the model still so weak at predicting its own data? You can discuss this with classmates next to you.

Maybe we need to add a parameter that accounts for buildings? After all, that seemed to be crucial information (though a bit redundant) to input in the simple model shown in the presentation. We will model this parameter as c[h] ~ Normal(cm, cs), where h is the index per building and cm and cs are hyperparameters.

```{r pressure, echo=FALSE}
####################### Model 3 ########################
#######################################################

##Compute and plot prior predictive checks
prior_model3 <- ulam(
  alist(
    ## this is the actual model
    y ~ poisson( lambda ),
    log(lambda) <- a + b*d + c[h],
    a ~ normal( am , as ),
    am ~ normal(0, 1),
    as ~ exponential(1),
    b ~ normal( bm , bs ),
    bm ~ normal(0, 1), #hyperpriors
    bs ~ exponential(1), #hyperpriors
    c[h] ~ normal( cm , cs ),
    cm ~ normal(0, 1), #hyperpriors
    cs ~ exponential(1) #hyperpriors
  ), data=data )
prior <- extract.prior(prior_model3, n=1000, pars=c(y))

y_ppc <- link(prior_model3, post=prior, data=data)

png(filename = "model3_prior_predictives.png", units = "in", width = 8, height = 8, res = 200)
plot(NULL, xlim = range(x_seq), ylim = y_limit, type = "n", 
     ylab="Density", xlab="Deaths (y)")
for (i in 500:600) {
  dens <- density(y_ppc[i, ])#, from = min(x_seq), to = max(x_seq))
  lines(dens$x, dens$y, col = col.alpha("deepskyblue2", 0.1))
  mean_dens <- density(colMeans(y_ppc), from = min(x_seq), to = max(x_seq))
  lines(mean_dens$x, mean_dens$y, col = col.alpha("darkorange"), lty=2, lwd=3)
  obs_dens = density(chol_map$deaths)
  lines(obs_dens$x, obs_dens$y, col = col.alpha("black"), lwd=3)
}
title(main="Model 3 Prior Predictive Check")
grid(nx = NULL, ny = NULL, col = "lightgray")
dev.off()
while (!is.null(dev.list()))  dev.off()


##sample model to get inference data (samples)
samp_model3 <- ulam(
  alist(
    ## this is the actual model
    y ~ poisson( lambda ),
    log(lambda) <- a + b*d + c[h],
    a ~ normal( am , as ),
    am ~ normal(0, 1),
    as ~ exponential(1),
    b ~ normal( bm , bs ),
    bm ~ normal(0, 1), 
    bs ~ exponential(1), 
    c[h] ~ normal( cm , cs ),
    cm ~ normal(0, 1), #hyperpriors
    cs ~ exponential(1) #hyperpriors
  ), data=data , chains=4 , log_lik=TRUE, iter=2000 )

prec <- precis(samp_model3, depth=2, prob=0.9)
prec <- data.frame(prec)
write.csv(prec, "model3_summary.csv")

extract <- rstan::extract #to avoid confict with other packages

png(filename = "model3_trankplots.png", units = "in", width = 12, height = 5, res = 200)
par(oma = c(0, 0, 3, 0))
trankplot(samp_model3, n_cols=2, lwd=3)
mtext("Model 3 trace rank plots", side=3, line=1, at=0.5, cex = 1.5, outer=TRUE)
while (!is.null(dev.list()))  dev.off()

##extract posterior predictive and plot
post <- extract.samples(samp_model3, n=1000)
y_pred <- link(samp_model3, post=post, data=data)

png(filename = "model3_posterior_predictives.png", units = "in", width = 8, height = 8, res = 200)
plot(NULL, xlim = range(x_seq), ylim = y_limit, type = "n",
     xlabel="Deaths (y)", ylabel="Density")
for (i in 500:600) {
  dens <- density(y_pred[i, ])#, from = min(x_seq), to = max(x_seq))
  lines(dens$x, dens$y, col = col.alpha("limegreen", 0.1))
  mean_dens <- density(colMeans(y_pred), from = min(x_seq), to = max(x_seq))
  lines(mean_dens$x, mean_dens$y, col = col.alpha("purple"), lty=2, lwd=3)
  obs_dens = density(chol_map$deaths)
  lines(obs_dens$x, obs_dens$y, col = col.alpha("black"), lwd=3)
}
title("Model 3 Posterior Predictive Check")
grid(nx = NULL, ny = NULL, col = "lightgray")
dev.off()


```

Do these results look more reasonable? Are the predictions transtaling better to the map?

```{r pressure, echo=FALSE}
## plot posterior predictive mean on map
post <- extract.samples(samp_model3, n=1000)
y_pred <- link(samp_model3, post=post, data=data)
chol_map$preds <- round(colMeans(y_pred), 1)
order_index <- order(chol_map$preds)
chol_map_ordered <- chol_map[order_index, ]
chol_map_ordered$preds <- factor(chol_map_ordered$preds, levels=unique(chol_map_ordered$preds))
color_palette <- viridis::plasma(length(unique(chol_map_ordered$preds)))
palette(color_palette)

png(filename="model3_preds_map.png", units="in", width=8, height=8, res=200)
plotRGB(snow_map, interpolate=TRUE, maxpixels=500000000)
points(chol_map_ordered$COORD_X, chol_map_ordered$COORD_Y, col=chol_map_ordered$preds, pch=19)
legend("topright", legend=unique(chol_map_ordered$preds), fill=color_palette, title="Predicted Deaths")
dev.off()

```


Finally, as a bonus, you can try add all information into a single model. Namely, you could make the intercept to vary across pump sectors, e.g. a[p] ~ normal(am, as). Or maybe you could have a varying slope, e.g. b[p]*d . Try below:

```{r pressure, echo=FALSE}


```
